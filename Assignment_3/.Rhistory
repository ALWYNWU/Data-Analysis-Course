cv_car = cv.tree(reg_tree)
plot(cv_car$size, cv_car$dev, type = "b")
tree.min <- which.min(cv_car$dev)
points(tree.min, cv_car$dev[tree.min], col = "red", cex = 2, pch = 20)
# (c)
cv_car = cv.tree(reg_tree)
plot(cv_car$size, cv_car$dev, type = "b")
tree.min <- which.min(cv_car$dev)
points(tree.min, cv_car$dev[tree.min], col = "red", cex = 2, pch = 20)
# (c)
cv_car = cv.tree(reg_tree)
plot(cv_car$size, cv_car$dev, type = "b")
prune.carseats = prune.tree(reg_tree, best = 5)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
library(ISLR)
set.seed(7)
# (a)
subset = sample(nrow(Carseats),nrow(Carseats)*0.8)
train = Carseats[subset,]
test = Carseats[-subset,]
# (b)
library(tree)
reg_tree = tree(Sales ~ ., data = train)
summary(reg_tree)
plot(reg_tree)
text(reg_tree, pretty = 0)
yhat <- predict(reg_tree, newdata = test)
mean((yhat - test$Sales)^2)
# (c)
cv_car = cv.tree(reg_tree)
plot(cv_car$size, cv_car$dev, type = "b")
prune.carseats = prune.tree(reg_tree, best = 5)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
# (c)
cv_car = cv.tree(reg_tree)
plot(cv_car$size, cv_car$dev, type = "b")
prune.carseats = prune.tree(reg_tree, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
yhat <- predict(prune.carseats, newdata = Carseats.test)
mean((yhat - Carseats.test$Sales)^2)
yhat = predict(prune.carseats, newdata = test)
mean((yhat - test$Sales)^2)
plot(cv_car$size, cv_car$dev, type = "b")
# (d)
bagging = randomForest(Sales ~ ., data = train, mtry = 10, ntree = 500, importance = TRUE)
library(randomForest)
install.packages('randomForest')
library(randomForest)
# (d)
bagging = randomForest(Sales ~ ., data = train, mtry = 10, ntree = 500, importance = TRUE)
yhat_bag = predict(bagging, newdata = test)
mean((yhat_bag - test$Sales)^2)
importance(bagging)
# (e)
rf = randomForest(Sales ~ ., data = train, mtry = 3, ntree = 500, importance = TRUE)
yhat.rf = predict(rf, newdata = test)
mean((yhat.rf - test$Sales)^2)
importance(rf)
require(ISLR); require(tidyverse); require(ggthemes)
require(caret); require(e1071)
install.packages('tidyverse')
install.packages("tidyverse")
require(ISLR); require(tidyverse); require(ggthemes)
install.packages('ggthemes')
install.packages('tidyverse')
install.packages("tidyverse")
require(ISLR); require(tidyverse); require(ggthemes)
require(caret); require(e1071)
# (a)
set.seed(17)
data('OJ')
index = sample(nrow(OJ), 800, replace = FALSE)
train = OJ[index,]
test = OJ[-index,]
# (b)
tree = tree(purchase ~ ., train)
library(tree)
# (b)
tree = tree(purchase ~ ., train)
# (b)
tree = tree(Purchase ~ ., train)
summary(tree)
# (c)
tree
# (d)
plot(tree)
text(tree, pretty=0)
purchase.test = oj$purchase[-index]
purchase.test = OJ$purchase[-index]
# (e)
pred = predict(tree, test, type="class")
table(pred, purchase.test)
# (a)
set.seed(17)
data('OJ')
index = sample(nrow(OJ), 800, replace = FALSE)
train = OJ[index,]
test = OJ[-index,]
purchase.test = OJ$purchase[-index]
# (b)
tree = tree(Purchase ~ ., train)
summary(tree)
# (c)
tree
# (d)
plot(tree)
text(tree, pretty=0)
# (e)
pred = predict(tree, test, type="class")
table(pred, purchase.test)
table(pred, test)
# (e)
pred = predict(tree, test, type="class")
table(pred, test)
pred.dim
# (e)
pred = predict(tree, test, type="class")
pred.dim
pred.shape
# (c)
tree
purchase.test = OJ$purchase[-index]
purchase.test = OJ$Purchase[-index]
# (e)
pred = predict(tree, test, type="class")
pred.shape
table(pred, test)
table(pred, purchase.test)
test_error = round(mean(pred != purchase.test)*100,2)
test_error
# (f)
cv_tree = cv.tree(tree, FUN = prune.misclass)
cv_tree
# (g)
plot(cv_tree$size, cv_tree$dev, type="b")
# (i)
pruned = prune.misclass(tree, best=7)
summary(pruned)
# (i)
pruned = prune.misclass(tree, best=4)
summary(pruned)
# (i)
pruned = prune.misclass(tree, best=2)
summary(pruned)
# (i)
pruned = prune.misclass(tree, best=5)
summary(pruned)
# (i)
pruned = prune.misclass(tree, best=5)
summary(pruned)
# (a)
set.seed(17)
data('OJ')
index = sample(nrow(OJ), 800, replace = FALSE)
train = OJ[index,]
test = OJ[-index,]
purchase.test = OJ$Purchase[-index]
# (b)
tree = tree(Purchase ~ ., train)
summary(tree)
# (c)
tree
# (d)
plot(tree)
text(tree, pretty=0)
# (e)
pred = predict(tree, test, type="class")
table(pred, purchase.test)
test_error = round(mean(pred != purchase.test)*100,2)
test_error
# (f)
cv_tree = cv.tree(tree, FUN = prune.misclass)
cv_tree
# (g)
plot(cv_tree$size, cv_tree$dev, type="b")
# (i)
pruned = prune.misclass(tree, best=5)
summary(pruned)
# (i)
pruned = prune.misclass(tree, best=2)
summary(pruned)
# (i)
pruned = prune.misclass(tree, best=4)
summary(pruned)
# (i)
pruned = prune.misclass(tree, best=5)
summary(pruned)
# (i)
pruned = prune.misclass(tree, best=6)
summary(pruned)
# (i)
pruned = prune.misclass(tree, best=2)
summary(pruned)
# (k)
prune.pred = predict(pruned, test, type="class")
table(prune.pred, purchase.test)
prune.test.error = round(mean(prune.pred != purchase.test)*100,2)
prune.test.error
error.df = data.frame(Model_type = c("unPruned","Pruned w/ Term.nodes=2"),Test_Error_rate = c(test_error, prune.test.error))
error.df
# (a)
Hitters <- na.omit(Hitters)
Hitters$Salary <- log(Hitters$Salary)
Hitters.dim
# (b)
index = 1:200
train = Hitters[index, ]
test = Hitters[-index, ]
# (c)
library(gbm)
install.packages('gbm')
# (c)
library(gbm)
set.seed(11)
pows = seq(-10, -0.2, by = 0.1)
lambdas = 10^pows
train.err = rep(NA, length(lambdas))
for (i in 1:length(lambdas)) {
boost.hitters = gbm(Salary ~ ., data = train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
pred.train = predict(boost.hitters, train, n.trees = 1000)
train.err[i] = mean((pred.train - train$Salary)^2)
}
plot(lambdas, train.err, type = "b", xlab = "Shrinkage values", ylab = "Training MSE")
# (d)
set.seed(11)
test.err <- rep(NA, length(lambdas))
for (i in 1:length(lambdas)) {
boost.hitters <- gbm(Salary ~ ., data = train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
yhat <- predict(boost.hitters, test, n.trees = 1000)
test.err[i] <- mean((yhat - test$Salary)^2)
}
plot(lambdas, test.err, type = "b", xlab = "Shrinkage values", ylab = "Test MSE")
# (e)
library(glmnet)
x = model.matrix(Salary~.,train)
x.test = model.matrix(Salary ~ . , test)
y = hitters.train$Salary
y = Hitters.train$Salary
y = train$Salary
ridge = glmnet(x,y,alpha=0)
ridge_predict = predict(ridge,s=0.01,x.test)
ridge_test_mse = mean((ridge_predict-test$Salary)^2)
ridge_test_mse
lasso = glmnet(x,y,alpha=1)
lasso_predict = predict(lasso,s=0.01,x.test)
lasso_test_mse = mean((lasso_predict-test$Salary)^2)
lasso_test_mse
# (f)
boost = gbm(Salary~.,data=train,distribution = "gaussian",n.trees = 1000,shrinkage=lambdas[which.min(test.error)])
# (f)
boost = gbm(Salary~.,data=train,distribution = "gaussian",n.trees = 1000,shrinkage=lambdas[which.min(test.err)])
summary(boost)
# (g)
set.seed(11)
bagging = randomForest(Salary~.,train,mtry=19,importance=TRUE)
bagg_predict = predict(bagging,test)
# (g)
library(randomForest)
set.seed(11)
bagging = randomForest(Salary~.,train,mtry=19,importance=TRUE)
bagg_predict = predict(bagging,test)
bagg_test_mse = mean((bagg_predict-test$Salary)^2)
bagg_test_mse
matrix(1:9, ncol = 3) %>%
dist() %>%
as.matrix()
q2_dist_vec <- c(
0,      0.3,    0.4,    0.7,
0.3,    0,      0.5,    0.8,
0.4,    0.5,    0,      0.45,
0.7,    0.8,    0.45,   0
)
matrix(q2_dist_vec, ncol = 4) %>%
as.dist() %>%
hclust(method='complete') %>%
ggdendrogram()
library(tidyverse)
library(ISLR)
library(ggdendro)
install.packages('ggdendro')
library(ggdendro)
matrix(q2_dist_vec, ncol = 4) %>%
as.dist() %>%
hclust(method='complete') %>%
ggdendrogram()
matrix(q2_dist_vec, ncol = 4)
as.dist()
hclust(method='complete')
ggdendrogram()
library(ggdendro)
matrix(q2_dist_vec, ncol = 4) %>%
as.dist() %>%
hclust(method='complete') %>%
ggdendrogram()
# (a)
x = cbind(c(1, 1, 0, 5, 6, 4), c(4, 3, 4, 1, 2, 0))
plot(x[,1], x[,2])
# (b)
set.seed(7)
labels = sample(2, nrow(x), replace = T)
labels
plot(x[, 1], x[, 2], col = (labels + 1), pch = 20, cex = 2)
# (c)
centroids = aggregate(x, list(Cluster = clusters), mean)
# (b)
set.seed(7)
clusters = sample(2, nrow(x), replace = T)
clusters
plot(x[, 1], x[, 2], col = (clusters + 1), pch = 20, cex = 2)
# (c)
centroids = aggregate(x, list(Cluster = clusters), mean)
centroids
# (d)
library(class)
clusters = knn(centroids[,2:3], X, factor(centroids[,1]))
clusters = knn(centroids[,2:3], x, factor(centroids[,1]))
clusters
col = rep("red", n)
col[clusters == 2] = "blue"
n = 6
col = rep("red", n)
col[clusters == 2] = "blue"
pch = rep(16, n)
pch[clusters == 2] = 17
plot(X, col = col, pch = pch)
plot(x, col = col, pch = pch)
# (e)
centroids = aggregate(x, list(Cluster = clusters), mean)
centroids
plot(x, col = col, pch = pch)
points(centroids[1,2:3], col = "red", pch = 8)
points(centroids[2,2:3], col = "blue", pch = 8)
clusters = knn(centroids[,2:3], x, factor(centroids[,1]))
clusters
centroids = aggregate(x, list(Cluster = clusters), mean)
centroids
# (a)
col = rep("red", n)
col[clusters == 2] = "blue"
pch = rep(16, n)
pch[clusters == 2] = 17
plot(X, col = col, pch = pch)
points(centroids[1,2:3], col = "red", pch = 8)
points(centroids[2,2:3], col = "blue", pch = 8)
# (a)
col = rep("yellow", n)
col[clusters == 2] = "green"
pch = rep(16, n)
pch[clusters == 2] = 17
plot(x, col = col, pch = pch)
points(centroids[1,2:3], col = "yellow", pch = 8)
points(centroids[2,2:3], col = "green", pch = 8)
# (a)
col = rep("red", n)
col[clusters == 2] = "green"
pch = rep(16, n)
pch[clusters == 2] = 17
plot(x, col = col, pch = pch)
points(centroids[1,2:3], col = "red", pch = 8)
# (a)
col = rep("orange", n)
col[clusters == 2] = "green"
pch = rep(16, n)
pch[clusters == 2] = 17
plot(x, col = col, pch = pch)
points(centroids[1,2:3], col = "red", pch = 8)
# (a)
col = rep("orange", n)
col[clusters == 2] = "green"
pch = rep(16, n)
pch[clusters == 2] = 17
plot(x, col = col, pch = pch)
points(centroids[1,2:3], col = "orange", pch = 8)
points(centroids[2,2:3], col = "green", pch = 8)
require(ISLR); require(tidyverse); require(ggthemes)
# (a)
set.seed(2)
complete = hclust(dist(USArrests), method = "complete")
plot(complete)
# (b)
cutree(complete, 3)
table(cutree(complete, 3))
# (c)
dsc = scale(USArrests)
hc.s.complete =  hclust(dist(dsc), method = "complete")
plot(hc.s.complete)
# (d)
cutree(hc.s.complete, 3)
table(cutree(hc.s.complete, 3))
table(cutree(hc.s.complete, 3), cutree(hc.complete, 3))
# (c)
dsc = scale(USArrests)
hc.s.complete =  hclust(dist(dsc), method = "complete")
plot(hc.s.complete)
# (d)
cutree(hc.s.complete, 3)
table(cutree(hc.s.complete, 3))
table(cutree(hc.s.complete, 3), cutree(hc.complete, 3))
# (d)
cutree(hc.s.complete, 3)
table(cutree(hc.s.complete, 3))
table(cutree(hc.s.complete, 3), cutree(complete, 3))
# (a)
X <- rbind(matrix(rnorm(20*50, mean = 0), nrow = 20),
matrix(rnorm(20*50, mean=0.7), nrow = 20),
matrix(rnorm(20*50, mean=1.4), nrow = 20))
# (a)
X <- rbind(matrix(rnorm(20*50, mean = 0), nrow = 20),
matrix(rnorm(20*50, mean=0.7), nrow = 20),
matrix(rnorm(20*50, mean=1.4), nrow = 20))
X
# (a)
sim_data = rbind(matrix(rnorm(20*50, mean = 0), nrow = 20),
matrix(rnorm(20*50, mean=0.7), nrow = 20),
matrix(rnorm(20*50, mean=1.4), nrow = 20))
# (b)
sim_data = prcomp(X)$x
plot(X.pca[,1:2], col=c(rep(1,20), rep(2,20), rep(3,20)))
plot(sim_data[,1:2], col=c(rep(1,20), rep(2,20), rep(3,20)))
# (c)
res = kmeans(sim_data, centers = 3)
true_class = c(rep(1,20), rep(2,20), rep(3,20))
table(res$cluster, true_class)
# (d)
res = kmeans(sim_data, centers = 2)
true_class = c(rep(1,20), rep(2,20), rep(3,20))
table(res$cluster, true_class)
#
#(e)
res = kmeans(sim_data, centers = 4)
true_class = c(rep(1,20), rep(2,20), rep(3,20))
table(res$cluster, true_class)
# (a)
sim_data = rbind(matrix(rnorm(20*50, mean = 0), nrow = 20),
matrix(rnorm(20*50, mean=0.7), nrow = 20),
matrix(rnorm(20*50, mean=1.4), nrow = 20))
# (b)
sim_data.pca = prcomp(X)$x
plot(sim_data.pca[,1:2], col=c(rep(1,20), rep(2,20), rep(3,20)))
# (c)
res = kmeans(sim_data, centers = 3)
true_class = c(rep(1,20), rep(2,20), rep(3,20))
table(res$cluster, true_class)
# (d)
res = kmeans(sim_data, centers = 2)
true_class = c(rep(1,20), rep(2,20), rep(3,20))
table(res$cluster, true_class)
# (e)
res = kmeans(sim_data, centers = 4)
true_class = c(rep(1,20), rep(2,20), rep(3,20))
table(res$cluster, true_class)
# (f)
res = kmeans(sim_data.pca[,1:2], centers = 3)
true = c(rep(1,20), rep(2,20), rep(3,20))
table(res$cluster, true_class)
# (g)
res = kmeans(scale(sim_data), centers = 3)
true = c(rep(1,20), rep(2,20), rep(3,20))
table(res$cluster, true_class)
# (a)
set.seed(7)
X1 = rnorm(100)
X1
X1 = rnorm(100,mean = 0,sd=1)
X1
X1 = rnorm(100,mean = 0)
X1
X1 = rnorm(100,mean = 0,sd=2)
X2 = rnorm(100,mean = 0,sd=2)
Z = rnorm(100,mean = 0,sd=2)
X1
X1 = rnorm(100,mean = 0,sd=1)
X2 = rnorm(100,mean = 0,sd=1)
Z = rnorm(100,mean = 0,sd=1)
y = sigmoid()
y = sigmoid(3*X1 + 3*X2) + (3*X1 - 3*X2)^2 + 0.3*Z
library(neuralnet)
install.packages('neuralnet')
library(neuralnet)
MSE = Null
MSE = NULL
data = data.frame(X1,X2,y)
index <- sample(1:100,round(0.9*100))
train <- data_set[index,]
data_set = data.frame(X1,X2,y)
index <- sample(1:100,round(0.9*100))
train <- data_set[index,]
test <- data_set[-index,]
# (a)
set.seed(7)
X1 = rnorm(100,mean = 0,sd=1)
X2 = rnorm(100,mean = 0,sd=1)
Z = rnorm(100,mean = 0,sd=1)
y = sigmoid(3*X1 + 3*X2) + (3*X1 - 3*X2)^2 + 0.3*Z
library(neuralnet)
K = 5
MSE = NULL
data_set = data.frame(X1,X2,y)
for (i in 1:10){
for (j in 1:K){
index <- sample(1:100,round(0.9*100))
train <- data_set[index,]
test <- data_set[-index,]
nn <- neuralnet(y~X1+X2,data=train,hidden=c(i),linear.output=T)
pred <- compute(nn,test)
#pr.nn <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
#test.cv.r <- (test.cv$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
}
}
